{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5001-kaggle-v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKPTihYVF-J6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkjgM8NeHeMG"
      },
      "source": [
        "# Define folder of the data\n",
        "DATA_FOLDER_PATH = 'data/'\n",
        "\n",
        "# read in train dataset\n",
        "train_set = pd.read_csv(\n",
        "  DATA_FOLDER_PATH + 'train.csv', \n",
        "  parse_dates=['date'], \n",
        "  index_col=\"date\",\n",
        "  dayfirst=True\n",
        ")\n",
        "\n",
        "# set date as index\n",
        "train_set.index = pd.to_datetime(train_set.index)\n",
        "test_set = pd.read_csv(\n",
        "  DATA_FOLDER_PATH + 'test.csv', \n",
        "  parse_dates=['date'], \n",
        "  index_col=\"date\",\n",
        "  dayfirst=True\n",
        ")\n",
        "\n",
        "# read in test dataset\n",
        "test_set.index = pd.to_datetime(test_set.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-gwG2W6sNwV"
      },
      "source": [
        "# define following functions used for data formatting\n",
        "def match_date(date, match_date_list):\n",
        "  if date.strftime(\"%Y-%m-%d\") in match_date_list:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def match_month(datetime, match_month_list):\n",
        "  if datetime.month in match_month_list:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def match_day_of_week(datetime, match_dayofweek_list):\n",
        "  if datetime.weekday() in match_dayofweek_list:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def match_hour_of_day(datetime, match_hourofday_list):\n",
        "  if datetime.hour in match_hourofday_list:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# define a list of hk public holidays in 2017-2018\n",
        "HK_PUBLIC_HOLIDAY_LIST = ['2017-01-01', '2017-01-02', '2017-01-28', '2017-01-29', '2017-01-30', '2017-01-31', '2017-04-05', '2017-04-14', '2017-04-15', '2017-04-17', '2017-05-01', '2017-05-03', '2017-05-30', '2017-07-01', '2017-10-01', '2017-10-02', '2017-10-05', '2017-10-28', '2017-12-25', '2017-12-26',\n",
        "                          '2018-01-01', '2018-02-16', '2018-02-17', '2018-02-18', '2018-02-19', '2018-03-30', '2018-03-31', '2018-04-02', '2018-04-05', '2018-05-01', '2018-05-22', '2018-06-18', '2018-07-02', '2018-09-25', '2018-10-01', '2018-10-17', '2018-12-25', '2018-12-26']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CfsFk4THxl7"
      },
      "source": [
        "# to expand dataset with more feature columns\n",
        "def expand_date_related_features(df):\n",
        "  df['week_day'] = df.index.dayofweek\n",
        "  df['hour'] = df.index.hour\n",
        "  df['holiday'] = df.index.map(lambda x: match_date(x, HK_PUBLIC_HOLIDAY_LIST))\n",
        "  df['weekend'] = df.index.map(lambda x: match_day_of_week(x, [5,6]))\n",
        "  for i in range(12):\n",
        "    df['month_' + str(i)] = df.index.to_series().map(lambda x: match_month(x, [i]))\n",
        "  for i in range(7):\n",
        "    df['day_of_week_' + str(i)] = df.index.to_series().map(lambda x: match_day_of_week(x, [i]))\n",
        "  for i in range(24):\n",
        "    df['hour_of_day_' + str(i)] = df.index.to_series().map(lambda x: match_hour_of_day(x, [i]))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcyPZIZ_VOHX"
      },
      "source": [
        "# to retrieve speed by a given date\n",
        "def get_speed_by_date(datetime, df):\n",
        "  d1 = df[df.index == datetime]\n",
        "  if len(list(d1.speed)) > 0:\n",
        "    return list(d1.speed)[0]\n",
        "  else:\n",
        "    d2 = df[df.week_day == datetime.weekday()][df.hour == datetime.hour][df.holiday == (1 if datetime.strftime(\"%Y-%m-%d\") in HK_PUBLIC_HOLIDAY_LIST else 0)]\n",
        "    if len(list(d2.speed)) > 0:\n",
        "      return d2.speed.mean()\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "# to expand dataset with prev and next hour speed as features\n",
        "def expand_speed_related_features(df, df_ref):\n",
        "  df['prev_hour_speed'] = df.index.to_series().map(lambda x: get_speed_by_date(x - timedelta(hours = 1), df_ref))\n",
        "  df['next_hour_speed'] = df.index.to_series().map(lambda x: get_speed_by_date(x + timedelta(hours = 1), df_ref))\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB1T96jts_HW",
        "outputId": "2a88c105-d680-4ad8-97c8-55bcd4dca2c4"
      },
      "source": [
        "# update train dataset and test dataset with the new features\n",
        "train_set = expand_date_related_features(train_set)\n",
        "test_set = expand_date_related_features(test_set)\n",
        "\n",
        "train_set = expand_speed_related_features(train_set, train_set)\n",
        "test_set = expand_speed_related_features(test_set, train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njk3s6jNryG1"
      },
      "source": [
        "# split out the feature columns used for training\n",
        "train_feature_list = [\n",
        "  'prev_hour_speed', 'next_hour_speed',\n",
        "  'holiday', 'weekend',\n",
        "  'month_0', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5',\n",
        "  'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n",
        "  'day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6',\n",
        "  'hour_of_day_0', 'hour_of_day_1', 'hour_of_day_2', 'hour_of_day_3', 'hour_of_day_4', 'hour_of_day_5', 'hour_of_day_6', \n",
        "  'hour_of_day_7', 'hour_of_day_8', 'hour_of_day_9', 'hour_of_day_10', 'hour_of_day_11', 'hour_of_day_12', 'hour_of_day_13',\n",
        "  'hour_of_day_14', 'hour_of_day_15', 'hour_of_day_16', 'hour_of_day_17', 'hour_of_day_18', 'hour_of_day_19', 'hour_of_day_20',\n",
        "  'hour_of_day_21', 'hour_of_day_22', 'hour_of_day_23'\n",
        "]\n",
        "\n",
        "# split out the label column\n",
        "train_label = ['speed']\n",
        "\n",
        "train_set_X = train_set[train_feature_list]\n",
        "train_set_Y = train_set[train_label]\n",
        "test_set_X = test_set[train_feature_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR7YTN2swQe5",
        "outputId": "20c31364-ab30-4e90-d25f-f7d2af81bd0f"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# rescale the prev and next speed value\n",
        "speed_scaler = RobustScaler()\n",
        "speed_scaler = speed_scaler.fit(train_set[['speed']].to_numpy())\n",
        "\n",
        "train_set_X['prev_hour_speed'] = speed_scaler.transform(train_set_X[['prev_hour_speed']])\n",
        "train_set_X['next_hour_speed'] = speed_scaler.transform(train_set_X[['next_hour_speed']])\n",
        "# train_set_Y['speed'] = speed_scaler.transform(train_set_Y[['speed']])\n",
        "\n",
        "test_set_X['prev_hour_speed'] = speed_scaler.transform(test_set_X[['prev_hour_speed']])\n",
        "test_set_X['next_hour_speed'] = speed_scaler.transform(test_set_X[['next_hour_speed']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrem1JHGUID"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# build a bi dierectional lstm model for training\n",
        "# with 256 units\n",
        "X_train_np = np.expand_dims(train_set_X.values.astype(np.float32), axis=1)\n",
        "y_train = train_set_Y\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(\n",
        "  keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(\n",
        "      units=128, \n",
        "      input_shape=(X_train_np.shape[1], X_train_np.shape[2])\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\n",
        "# add one more output layer with 1 unit\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZtztOeXGnVb"
      },
      "source": [
        "# train model using train_dataset\n",
        "history = model.fit(\n",
        "    X_train_np, y_train, \n",
        "    epochs=50, \n",
        "    batch_size=20, \n",
        "    validation_split=0.1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbgxWLAhIC-6"
      },
      "source": [
        "# apply the model to the test set, and output the result\n",
        "X_test_np = np.expand_dims(test_set_X.values.astype(np.float32), axis=1)\n",
        "\n",
        "df_test_y = model.predict(X_test_np)\n",
        "nn_df = pd.DataFrame(df_test_y, columns=['speed'], index=test_set.id)\n",
        "nn_df['speed'] = nn_df[['speed']]\n",
        "nn_df.to_csv(DATA_FOLDER_PATH + 'result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}